{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import modelutils\n",
    "import utils\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import callbacks\n",
    "import pprint\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the latest dataset-paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180803-1734-voxelgrid-dataset.p\n",
      "20180803-1711-pointcloud-dataset.p\n"
     ]
    }
   ],
   "source": [
    "dataset_name_voxelgrid = sorted([x for x in glob.glob(\"*.p\") if \"voxelgrid-dataset\" in x])[-1]\n",
    "print(dataset_name_voxelgrid)\n",
    "\n",
    "dataset_name_pointcloud = sorted([x for x in glob.glob(\"*.p\") if \"pointcloud-dataset\" in x])[-1]\n",
    "print(dataset_name_pointcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = callbacks.TensorBoard()\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_history(model, history, name):\n",
    "    \n",
    "    print(\"Saving model and history...\")\n",
    "    \n",
    "    datetime_string = utils.get_datetime_string()\n",
    "    \n",
    "    model_name = datetime_string + \"-\" + name + \"-model.h5\"\n",
    "    model_voxnet.save(model_name)\n",
    "    print(\"Saved model to\" + model_name)\n",
    "\n",
    "    \n",
    "    history_name = datetime_string + \"-\" + name + \"-history.p\"\n",
    "    pickle.dump(history.history, open(history_name, \"wb\"))\n",
    "    print(\"Saved history to\" + history_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VoxNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "{   'dataset_size_test': 1000,\n",
      "    'dataset_size_train': 6000,\n",
      "    'input_type': 'voxelgrid',\n",
      "    'output_targets': ['height', 'weight'],\n",
      "    'random_seed': 666,\n",
      "    'voxel_size_meters': 0.1,\n",
      "    'voxelgrid_random_rotation': True,\n",
      "    'voxelgrid_target_shape': (32, 32, 32)}\n"
     ]
    }
   ],
   "source": [
    "dataset_name = dataset_name_voxelgrid\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "(x_input_train, y_output_train), (x_input_test, y_output_test), dataset_parameters = pickle.load(open(dataset_name, \"rb\"))\n",
    "pp.pprint(dataset_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 32, 32, 32, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 14, 14, 14, 32)    4032      \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 12, 12, 12, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 6, 6, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               884864    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 916,834\n",
      "Trainable params: 916,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "6000/6000 [==============================] - 2s 394us/step - loss: 160.8275 - mean_absolute_error: 7.4798 - val_loss: 345.1331 - val_mean_absolute_error: 14.4182\n",
      "Epoch 2/50\n",
      "6000/6000 [==============================] - 2s 333us/step - loss: 92.3465 - mean_absolute_error: 6.4965 - val_loss: 157.7444 - val_mean_absolute_error: 9.0687\n",
      "Epoch 3/50\n",
      "6000/6000 [==============================] - 2s 346us/step - loss: 87.7800 - mean_absolute_error: 6.2931 - val_loss: 39.2473 - val_mean_absolute_error: 4.1526\n",
      "Epoch 4/50\n",
      "6000/6000 [==============================] - 2s 333us/step - loss: 75.0892 - mean_absolute_error: 5.8098 - val_loss: 56.2891 - val_mean_absolute_error: 5.0726\n",
      "Epoch 5/50\n",
      "6000/6000 [==============================] - 2s 318us/step - loss: 65.4562 - mean_absolute_error: 5.3594 - val_loss: 70.7010 - val_mean_absolute_error: 5.7560\n",
      "Epoch 6/50\n",
      "6000/6000 [==============================] - 2s 312us/step - loss: 60.2147 - mean_absolute_error: 5.1484 - val_loss: 81.6450 - val_mean_absolute_error: 6.5368\n",
      "Epoch 7/50\n",
      "6000/6000 [==============================] - 2s 324us/step - loss: 55.3553 - mean_absolute_error: 4.9338 - val_loss: 38.8002 - val_mean_absolute_error: 4.1879\n",
      "Epoch 8/50\n",
      "6000/6000 [==============================] - 2s 332us/step - loss: 52.3547 - mean_absolute_error: 4.7888 - val_loss: 103.8153 - val_mean_absolute_error: 7.4331\n",
      "Epoch 9/50\n",
      "6000/6000 [==============================] - 2s 307us/step - loss: 47.7918 - mean_absolute_error: 4.5851 - val_loss: 27.0885 - val_mean_absolute_error: 3.2006\n",
      "Epoch 10/50\n",
      "6000/6000 [==============================] - 2s 309us/step - loss: 45.0255 - mean_absolute_error: 4.4512 - val_loss: 40.8963 - val_mean_absolute_error: 4.4913\n",
      "Epoch 11/50\n",
      "6000/6000 [==============================] - 2s 311us/step - loss: 42.9074 - mean_absolute_error: 4.3522 - val_loss: 29.9075 - val_mean_absolute_error: 3.3529\n",
      "Epoch 12/50\n",
      "6000/6000 [==============================] - 2s 322us/step - loss: 41.2536 - mean_absolute_error: 4.3007 - val_loss: 71.3746 - val_mean_absolute_error: 5.9290\n",
      "Epoch 13/50\n",
      "6000/6000 [==============================] - 2s 322us/step - loss: 38.6723 - mean_absolute_error: 4.1582 - val_loss: 44.1982 - val_mean_absolute_error: 4.2706\n",
      "Epoch 14/50\n",
      "6000/6000 [==============================] - 2s 316us/step - loss: 37.0679 - mean_absolute_error: 4.0859 - val_loss: 42.1394 - val_mean_absolute_error: 4.1963\n",
      "Epoch 15/50\n",
      "6000/6000 [==============================] - 2s 303us/step - loss: 34.3507 - mean_absolute_error: 3.9053 - val_loss: 18.5175 - val_mean_absolute_error: 2.4477\n",
      "Epoch 16/50\n",
      "6000/6000 [==============================] - 2s 309us/step - loss: 32.7706 - mean_absolute_error: 3.8170 - val_loss: 20.3363 - val_mean_absolute_error: 2.6252\n",
      "Epoch 17/50\n",
      "6000/6000 [==============================] - 2s 307us/step - loss: 31.4022 - mean_absolute_error: 3.7163 - val_loss: 35.3730 - val_mean_absolute_error: 3.7685\n",
      "Epoch 18/50\n",
      "6000/6000 [==============================] - 2s 288us/step - loss: 30.5758 - mean_absolute_error: 3.6796 - val_loss: 20.2428 - val_mean_absolute_error: 2.9228\n",
      "Epoch 19/50\n",
      "6000/6000 [==============================] - 2s 298us/step - loss: 29.5149 - mean_absolute_error: 3.6289 - val_loss: 39.0656 - val_mean_absolute_error: 4.1117\n",
      "Epoch 20/50\n",
      "6000/6000 [==============================] - 2s 307us/step - loss: 28.6497 - mean_absolute_error: 3.5630 - val_loss: 30.7182 - val_mean_absolute_error: 3.2660\n",
      "Epoch 21/50\n",
      "6000/6000 [==============================] - 2s 296us/step - loss: 27.2663 - mean_absolute_error: 3.4727 - val_loss: 18.5464 - val_mean_absolute_error: 2.6375\n",
      "Epoch 22/50\n",
      "6000/6000 [==============================] - 2s 293us/step - loss: 26.8463 - mean_absolute_error: 3.4392 - val_loss: 22.7868 - val_mean_absolute_error: 2.7932\n",
      "Epoch 23/50\n",
      "6000/6000 [==============================] - 2s 276us/step - loss: 26.6077 - mean_absolute_error: 3.4188 - val_loss: 26.1844 - val_mean_absolute_error: 2.9263\n",
      "Epoch 24/50\n",
      "6000/6000 [==============================] - 2s 292us/step - loss: 26.0973 - mean_absolute_error: 3.3764 - val_loss: 25.8679 - val_mean_absolute_error: 2.9818\n",
      "Epoch 25/50\n",
      "6000/6000 [==============================] - 2s 290us/step - loss: 26.1414 - mean_absolute_error: 3.3913 - val_loss: 37.8068 - val_mean_absolute_error: 3.8006\n",
      "Epoch 26/50\n",
      "6000/6000 [==============================] - 2s 282us/step - loss: 25.3981 - mean_absolute_error: 3.3423 - val_loss: 31.4028 - val_mean_absolute_error: 3.3754\n",
      "Epoch 27/50\n",
      "6000/6000 [==============================] - 2s 272us/step - loss: 24.8560 - mean_absolute_error: 3.3089 - val_loss: 21.8100 - val_mean_absolute_error: 2.6612\n",
      "Epoch 28/50\n",
      "6000/6000 [==============================] - 2s 276us/step - loss: 24.7623 - mean_absolute_error: 3.2937 - val_loss: 43.0523 - val_mean_absolute_error: 4.1688\n",
      "Epoch 29/50\n",
      "6000/6000 [==============================] - 2s 280us/step - loss: 23.9541 - mean_absolute_error: 3.2304 - val_loss: 53.6570 - val_mean_absolute_error: 4.7897\n",
      "Epoch 30/50\n",
      "6000/6000 [==============================] - 2s 298us/step - loss: 24.1349 - mean_absolute_error: 3.2593 - val_loss: 29.5713 - val_mean_absolute_error: 3.3225\n",
      "Epoch 31/50\n",
      "6000/6000 [==============================] - 2s 279us/step - loss: 23.9819 - mean_absolute_error: 3.2246 - val_loss: 30.7922 - val_mean_absolute_error: 3.4162\n",
      "Epoch 32/50\n",
      "6000/6000 [==============================] - 2s 278us/step - loss: 22.8819 - mean_absolute_error: 3.1535 - val_loss: 21.9905 - val_mean_absolute_error: 2.7477\n",
      "Epoch 33/50\n",
      "6000/6000 [==============================] - 2s 289us/step - loss: 22.5480 - mean_absolute_error: 3.1397 - val_loss: 36.7809 - val_mean_absolute_error: 3.7980\n",
      "Epoch 34/50\n",
      "6000/6000 [==============================] - 2s 268us/step - loss: 22.0278 - mean_absolute_error: 3.1011 - val_loss: 65.4985 - val_mean_absolute_error: 5.5089\n",
      "Epoch 35/50\n",
      "6000/6000 [==============================] - 2s 277us/step - loss: 22.3181 - mean_absolute_error: 3.0983 - val_loss: 57.5942 - val_mean_absolute_error: 5.0996\n",
      "Epoch 36/50\n",
      "6000/6000 [==============================] - 2s 276us/step - loss: 21.9822 - mean_absolute_error: 3.0961 - val_loss: 33.2063 - val_mean_absolute_error: 3.3855\n",
      "Epoch 37/50\n",
      "6000/6000 [==============================] - 2s 280us/step - loss: 21.6321 - mean_absolute_error: 3.0682 - val_loss: 24.4330 - val_mean_absolute_error: 2.7957\n",
      "Epoch 38/50\n",
      "6000/6000 [==============================] - 2s 271us/step - loss: 21.0381 - mean_absolute_error: 3.0182 - val_loss: 23.7152 - val_mean_absolute_error: 2.7906\n",
      "Epoch 39/50\n",
      "6000/6000 [==============================] - 2s 283us/step - loss: 20.6117 - mean_absolute_error: 2.9990 - val_loss: 23.0961 - val_mean_absolute_error: 2.8190\n",
      "Epoch 40/50\n",
      "6000/6000 [==============================] - 2s 266us/step - loss: 20.8511 - mean_absolute_error: 3.0043 - val_loss: 54.7790 - val_mean_absolute_error: 4.7764\n",
      "Epoch 41/50\n",
      "6000/6000 [==============================] - 2s 367us/step - loss: 20.5472 - mean_absolute_error: 2.9795 - val_loss: 30.9976 - val_mean_absolute_error: 3.2391\n",
      "Epoch 42/50\n",
      "6000/6000 [==============================] - 2s 337us/step - loss: 19.7370 - mean_absolute_error: 2.9305 - val_loss: 24.7592 - val_mean_absolute_error: 2.8804\n",
      "Epoch 43/50\n",
      "6000/6000 [==============================] - 2s 346us/step - loss: 19.6664 - mean_absolute_error: 2.9124 - val_loss: 36.3846 - val_mean_absolute_error: 3.5318\n",
      "Epoch 44/50\n",
      "6000/6000 [==============================] - 2s 350us/step - loss: 19.3951 - mean_absolute_error: 2.9080 - val_loss: 73.1459 - val_mean_absolute_error: 5.9763\n",
      "Epoch 45/50\n",
      "6000/6000 [==============================] - 2s 273us/step - loss: 19.1575 - mean_absolute_error: 2.8888 - val_loss: 63.6512 - val_mean_absolute_error: 5.3429\n",
      "Epoch 46/50\n",
      "6000/6000 [==============================] - 2s 327us/step - loss: 19.0947 - mean_absolute_error: 2.8675 - val_loss: 80.7293 - val_mean_absolute_error: 6.3619\n",
      "Epoch 47/50\n",
      "6000/6000 [==============================] - 2s 380us/step - loss: 18.0375 - mean_absolute_error: 2.8017 - val_loss: 92.4492 - val_mean_absolute_error: 6.5291\n",
      "Epoch 48/50\n",
      "6000/6000 [==============================] - 2s 314us/step - loss: 18.4114 - mean_absolute_error: 2.8206 - val_loss: 28.2240 - val_mean_absolute_error: 3.0700\n",
      "Epoch 49/50\n",
      "6000/6000 [==============================] - 2s 356us/step - loss: 18.2530 - mean_absolute_error: 2.8081 - val_loss: 36.8825 - val_mean_absolute_error: 3.5754\n",
      "Epoch 50/50\n",
      "6000/6000 [==============================] - 2s 336us/step - loss: 17.7037 - mean_absolute_error: 2.7730 - val_loss: 75.9622 - val_mean_absolute_error: 6.0246\n",
      "Saving model and history...\n",
      "Saved model to20180804-0930-voxnet-model.h5\n",
      "Saved history to20180804-0930-voxnet-history.p\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 32)\n",
    "output_size = 2 \n",
    "model_voxnet = modelutils.create_voxnet_model_homepage(input_shape, output_size)\n",
    "model_voxnet.summary()\n",
    "\n",
    " # Compile the model.\n",
    "model_voxnet.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "# Train the model.\n",
    "history = model_voxnet.fit(\n",
    "    x_input_train, y_output_train,\n",
    "    epochs=50,\n",
    "    validation_data=(x_input_test, y_output_test),\n",
    "    callbacks=[tensorboard_callback]\n",
    "    )\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "save_model_and_history(model_voxnet, history, \"voxnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PointNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "{   'dataset_size_test': 500,\n",
      "    'dataset_size_train': 3000,\n",
      "    'input_type': 'pointcloud',\n",
      "    'output_targets': ['height', 'weight'],\n",
      "    'pointcloud_random_rotation': True,\n",
      "    'pointcloud_target_size': 30000,\n",
      "    'random_seed': 666}\n",
      "Ignoring shape: (27288, 4)\n",
      "Ignoring shape: (26302, 4)\n",
      "Ignoring shape: (29216, 4)\n",
      "Ignoring shape: (29223, 4)\n",
      "Ignoring shape: (28849, 4)\n",
      "Ignoring shape: (29223, 4)\n",
      "Ignoring shape: (29889, 4)\n",
      "Ignoring shape: (29297, 4)\n",
      "Ignoring shape: (26563, 4)\n",
      "Ignoring shape: (29610, 4)\n",
      "Ignoring shape: (29743, 4)\n",
      "Ignoring shape: (29172, 4)\n",
      "Ignoring shape: (29297, 4)\n",
      "Ignoring shape: (29501, 4)\n",
      "Ignoring shape: (26232, 4)\n",
      "Ignoring shape: (29782, 4)\n",
      "Ignoring shape: (29648, 4)\n",
      "Ignoring shape: (29519, 4)\n",
      "Ignoring shape: (29443, 4)\n",
      "Ignoring shape: (29297, 4)\n",
      "Ignoring shape: (27134, 4)\n",
      "Ignoring shape: (29443, 4)\n",
      "Ignoring shape: (26793, 4)\n",
      "Ignoring shape: (28849, 4)\n",
      "Ignoring shape: (29743, 4)\n",
      "Ignoring shape: (29694, 4)\n",
      "Ignoring shape: (29216, 4)\n",
      "Ignoring shape: (27081, 4)\n",
      "Ignoring shape: (26949, 4)\n",
      "Ignoring shape: (27727, 4)\n",
      "Ignoring shape: (26232, 4)\n",
      "Ignoring shape: (27807, 4)\n",
      "Ignoring shape: (27709, 4)\n",
      "Ignoring shape: (29501, 4)\n",
      "Ignoring shape: (26965, 4)\n",
      "Ignoring shape: (29743, 4)\n",
      "Ignoring shape: (29297, 4)\n",
      "Ignoring shape: (29443, 4)\n",
      "Ignoring shape: (29297, 4)\n",
      "Ignoring shape: (29519, 4)\n",
      "Ignoring shape: (26228, 4)\n",
      "Ignoring shape: (27288, 4)\n",
      "Ignoring shape: (29223, 4)\n",
      "Ignoring shape: (29537, 4)\n",
      "Ignoring shape: (26563, 4)\n",
      "Ignoring shape: (27365, 4)\n",
      "Ignoring shape: (26304, 4)\n",
      "Ignoring shape: (27453, 4)\n",
      "Ignoring shape: (27725, 4)\n",
      "Ignoring shape: (29270, 4)\n",
      "Ignoring shape: (29172, 4)\n",
      "Ignoring shape: (29648, 4)\n",
      "Ignoring shape: (29705, 4)\n",
      "Ignoring shape: (29519, 4)\n",
      "Ignoring shape: (27838, 4)\n",
      "Ignoring shape: (28408, 4)\n",
      "Ignoring shape: (29920, 4)\n",
      "Ignoring shape: (29885, 4)\n",
      "Ignoring shape: (29705, 4)\n",
      "Ignoring shape: (26249, 4)\n",
      "Ignoring shape: (29223, 4)\n",
      "Ignoring shape: (26124, 4)\n",
      "Ignoring shape: (29927, 4)\n",
      "Ignoring shape: (29537, 4)\n",
      "Ignoring shape: (29582, 4)\n",
      "Ignoring shape: (26793, 4)\n",
      "Ignoring shape: (29677, 4)\n",
      "Ignoring shape: (29172, 4)\n",
      "Ignoring shape: (26949, 4)\n",
      "Ignoring shape: (29566, 4)\n",
      "Ignoring shape: (26124, 4)\n",
      "Ignoring shape: (29172, 4)\n",
      "Ignoring shape: (29891, 4)\n",
      "Ignoring shape: (27838, 4)\n",
      "Ignoring shape: (29537, 4)\n",
      "Ignoring shape: (29297, 4)\n",
      "Ignoring shape: (29566, 4)\n",
      "Ignoring shape: (29927, 4)\n",
      "Training data input shape: (2922, 30000, 3)\n",
      "Training data output shape: (2922, 2)\n",
      "Testing data input shape: (2922, 30000, 3)\n",
      "Testing data output shape: (2922, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = dataset_name_pointcloud\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "(x_input_train, y_output_train), (x_input_test, y_output_test), dataset_parameters = pickle.load(open(dataset_name, \"rb\"))\n",
    "pp.pprint(dataset_parameters)\n",
    "\n",
    "def transform(x_input, y_output):\n",
    "\n",
    "    x_input_transformed = []\n",
    "    y_output_transformed = []\n",
    "    for input_sample, output_sample in zip(x_input_train, y_output_train):\n",
    "        if input_sample.shape[0] == 30000:\n",
    "            x_input_transformed.append(input_sample[:,0:3])\n",
    "            y_output_transformed.append(output_sample)\n",
    "        else:\n",
    "            # TODO maybe do some padding here?\n",
    "            print(\"Ignoring shape:\", input_sample.shape)\n",
    "            \n",
    "    x_input_transformed = np.array(x_input_transformed)\n",
    "    y_output_transformed = np.array(y_output_transformed)\n",
    "    return x_input_transformed, y_output_transformed\n",
    "    \n",
    "x_input_train, y_output_train = transform(x_input_train, y_output_train)\n",
    "x_input_test, y_output_test = transform(x_input_test, y_output_test)\n",
    "\n",
    "print(\"Training data input shape:\", x_input_train.shape)\n",
    "print(\"Training data output shape:\", y_output_train.shape)\n",
    "print(\"Testing data input shape:\", x_input_test.shape)\n",
    "print(\"Testing data output shape:\", y_output_test.shape)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30000, 3)          0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 30000, 3)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 30000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 30000, 64)         4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30000, 64)         256       \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 30000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 30000, 64)         4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 30000, 128)        8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 30000, 1024)       132096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30000, 1024)       4096      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1, 512)            524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1, 256)            131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1, 2)              514       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 814,082\n",
      "Trainable params: 809,858\n",
      "Non-trainable params: 4,224\n",
      "_________________________________________________________________\n",
      "Train on 2922 samples, validate on 2922 samples\n",
      "Epoch 1/50\n",
      "2922/2922 [==============================] - 424s 145ms/step - loss: 2272.7552 - mean_absolute_error: 35.1030 - val_loss: 855.0454 - val_mean_absolute_error: 20.8447\n",
      "Epoch 2/50\n",
      "2922/2922 [==============================] - 421s 144ms/step - loss: 206.2481 - mean_absolute_error: 9.0731 - val_loss: 48.3339 - val_mean_absolute_error: 4.9635\n",
      "Epoch 3/50\n",
      "2922/2922 [==============================] - 424s 145ms/step - loss: 121.0500 - mean_absolute_error: 7.0672 - val_loss: 45.1719 - val_mean_absolute_error: 4.7258\n",
      "Epoch 4/50\n",
      "2922/2922 [==============================] - 421s 144ms/step - loss: 113.2480 - mean_absolute_error: 6.8201 - val_loss: 40.6574 - val_mean_absolute_error: 4.3470\n",
      "Epoch 5/50\n",
      "2922/2922 [==============================] - 420s 144ms/step - loss: 104.6072 - mean_absolute_error: 6.4975 - val_loss: 39.3197 - val_mean_absolute_error: 4.3877\n",
      "Epoch 6/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 100.3791 - mean_absolute_error: 6.4378 - val_loss: 45.6697 - val_mean_absolute_error: 4.4762\n",
      "Epoch 7/50\n",
      "2922/2922 [==============================] - 419s 143ms/step - loss: 94.6163 - mean_absolute_error: 6.2334 - val_loss: 45.4095 - val_mean_absolute_error: 4.5516\n",
      "Epoch 8/50\n",
      "2922/2922 [==============================] - 421s 144ms/step - loss: 91.8704 - mean_absolute_error: 6.1845 - val_loss: 44.2272 - val_mean_absolute_error: 4.4855\n",
      "Epoch 9/50\n",
      "2922/2922 [==============================] - 419s 144ms/step - loss: 89.4357 - mean_absolute_error: 6.1344 - val_loss: 39.2537 - val_mean_absolute_error: 4.4196\n",
      "Epoch 10/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 85.3867 - mean_absolute_error: 5.9473 - val_loss: 173.1729 - val_mean_absolute_error: 5.5080\n",
      "Epoch 11/50\n",
      "2922/2922 [==============================] - 420s 144ms/step - loss: 89.4198 - mean_absolute_error: 6.1056 - val_loss: 35.9655 - val_mean_absolute_error: 4.0965\n",
      "Epoch 12/50\n",
      "2922/2922 [==============================] - 419s 143ms/step - loss: 81.6437 - mean_absolute_error: 5.8628 - val_loss: 47.7930 - val_mean_absolute_error: 4.4613\n",
      "Epoch 13/50\n",
      "2922/2922 [==============================] - 419s 144ms/step - loss: 77.2345 - mean_absolute_error: 5.6834 - val_loss: 41.1399 - val_mean_absolute_error: 4.3405\n",
      "Epoch 14/50\n",
      "2922/2922 [==============================] - 420s 144ms/step - loss: 80.5083 - mean_absolute_error: 5.7892 - val_loss: 34.1963 - val_mean_absolute_error: 4.1288\n",
      "Epoch 15/50\n",
      "2922/2922 [==============================] - 420s 144ms/step - loss: 79.2811 - mean_absolute_error: 5.7382 - val_loss: 35.3055 - val_mean_absolute_error: 4.0960\n",
      "Epoch 16/50\n",
      "2922/2922 [==============================] - 420s 144ms/step - loss: 74.0997 - mean_absolute_error: 5.5953 - val_loss: 35.9882 - val_mean_absolute_error: 4.2130\n",
      "Epoch 17/50\n",
      "2922/2922 [==============================] - 420s 144ms/step - loss: 75.2362 - mean_absolute_error: 5.6185 - val_loss: 37.9578 - val_mean_absolute_error: 4.2028\n",
      "Epoch 18/50\n",
      "2922/2922 [==============================] - 419s 143ms/step - loss: 73.6336 - mean_absolute_error: 5.5472 - val_loss: 55.6522 - val_mean_absolute_error: 4.7380\n",
      "Epoch 19/50\n",
      "2922/2922 [==============================] - 419s 143ms/step - loss: 76.2221 - mean_absolute_error: 5.6319 - val_loss: 40.8137 - val_mean_absolute_error: 4.3083\n",
      "Epoch 20/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 76.4113 - mean_absolute_error: 5.6282 - val_loss: 38.0380 - val_mean_absolute_error: 4.1784\n",
      "Epoch 21/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 71.8123 - mean_absolute_error: 5.5061 - val_loss: 37.8280 - val_mean_absolute_error: 4.1838\n",
      "Epoch 22/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 71.6383 - mean_absolute_error: 5.5157 - val_loss: 45.7678 - val_mean_absolute_error: 4.5131\n",
      "Epoch 23/50\n",
      "2922/2922 [==============================] - 419s 144ms/step - loss: 69.2972 - mean_absolute_error: 5.4004 - val_loss: 32.3859 - val_mean_absolute_error: 3.9959\n",
      "Epoch 24/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 70.4588 - mean_absolute_error: 5.4405 - val_loss: 31.1355 - val_mean_absolute_error: 3.8807\n",
      "Epoch 25/50\n",
      "2922/2922 [==============================] - 419s 143ms/step - loss: 67.8232 - mean_absolute_error: 5.3836 - val_loss: 35.2493 - val_mean_absolute_error: 4.1075\n",
      "Epoch 26/50\n",
      "2922/2922 [==============================] - 419s 143ms/step - loss: 69.8856 - mean_absolute_error: 5.4474 - val_loss: 28.8501 - val_mean_absolute_error: 3.7156\n",
      "Epoch 27/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 71.4493 - mean_absolute_error: 5.4815 - val_loss: 30.4256 - val_mean_absolute_error: 3.8567\n",
      "Epoch 28/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 66.5330 - mean_absolute_error: 5.3416 - val_loss: 26.3157 - val_mean_absolute_error: 3.5271\n",
      "Epoch 29/50\n",
      "2922/2922 [==============================] - 417s 143ms/step - loss: 66.1989 - mean_absolute_error: 5.2536 - val_loss: 33.5747 - val_mean_absolute_error: 4.0220\n",
      "Epoch 30/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 66.9486 - mean_absolute_error: 5.3368 - val_loss: 41.9139 - val_mean_absolute_error: 4.3725\n",
      "Epoch 31/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 68.7851 - mean_absolute_error: 5.3992 - val_loss: 35.8116 - val_mean_absolute_error: 4.1076\n",
      "Epoch 32/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 67.4173 - mean_absolute_error: 5.2878 - val_loss: 39.3134 - val_mean_absolute_error: 4.1798\n",
      "Epoch 33/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 68.4702 - mean_absolute_error: 5.4020 - val_loss: 38.7730 - val_mean_absolute_error: 3.7801\n",
      "Epoch 34/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 69.0417 - mean_absolute_error: 5.4330 - val_loss: 32.5607 - val_mean_absolute_error: 3.9083\n",
      "Epoch 35/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 70.7585 - mean_absolute_error: 5.4836 - val_loss: 36.0491 - val_mean_absolute_error: 4.0570\n",
      "Epoch 36/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 68.0266 - mean_absolute_error: 5.3612 - val_loss: 38.7010 - val_mean_absolute_error: 4.1939\n",
      "Epoch 37/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 64.6311 - mean_absolute_error: 5.2704 - val_loss: 33.3836 - val_mean_absolute_error: 3.9837\n",
      "Epoch 38/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 65.1940 - mean_absolute_error: 5.2733 - val_loss: 30.4468 - val_mean_absolute_error: 3.8215\n",
      "Epoch 39/50\n",
      "2922/2922 [==============================] - 419s 143ms/step - loss: 64.9391 - mean_absolute_error: 5.2547 - val_loss: 35.5225 - val_mean_absolute_error: 4.0424\n",
      "Epoch 40/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 61.1554 - mean_absolute_error: 5.1072 - val_loss: 31.3109 - val_mean_absolute_error: 3.8406\n",
      "Epoch 41/50\n",
      "2922/2922 [==============================] - 419s 143ms/step - loss: 65.0864 - mean_absolute_error: 5.2081 - val_loss: 30.9506 - val_mean_absolute_error: 3.7818\n",
      "Epoch 42/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 63.1863 - mean_absolute_error: 5.1786 - val_loss: 34.6120 - val_mean_absolute_error: 3.9823\n",
      "Epoch 43/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 60.9876 - mean_absolute_error: 5.1188 - val_loss: 27.9139 - val_mean_absolute_error: 3.6108\n",
      "Epoch 44/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 66.0183 - mean_absolute_error: 5.3003 - val_loss: 34.3162 - val_mean_absolute_error: 4.0599\n",
      "Epoch 45/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 64.1018 - mean_absolute_error: 5.2062 - val_loss: 31.3607 - val_mean_absolute_error: 3.8653\n",
      "Epoch 46/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 64.8090 - mean_absolute_error: 5.2586 - val_loss: 29.5495 - val_mean_absolute_error: 3.7204\n",
      "Epoch 47/50\n",
      "2922/2922 [==============================] - 418s 143ms/step - loss: 63.5735 - mean_absolute_error: 5.1657 - val_loss: 31.2942 - val_mean_absolute_error: 3.8562\n",
      "Epoch 48/50\n",
      "2922/2922 [==============================] - 419s 143ms/step - loss: 66.4932 - mean_absolute_error: 5.2778 - val_loss: 32.8813 - val_mean_absolute_error: 3.9156\n",
      "Epoch 49/50\n",
      "2922/2922 [==============================] - 419s 143ms/step - loss: 63.3770 - mean_absolute_error: 5.1982 - val_loss: 38.5608 - val_mean_absolute_error: 4.1918\n",
      "Epoch 50/50\n",
      "2922/2922 [==============================] - 419s 143ms/step - loss: 64.0101 - mean_absolute_error: 5.2075 - val_loss: 35.2535 - val_mean_absolute_error: 3.9445\n",
      "Saving model and history...\n",
      "Saved model to20180804-1520-pointnet-model.h5\n",
      "Saved history to20180804-1520-pointnet-history.p\n"
     ]
    }
   ],
   "source": [
    "input_shape = (30000, 3)\n",
    "output_size = 2 \n",
    "model_pointnet = modelutils.create_point_net(input_shape, output_size)\n",
    "model_pointnet.summary()\n",
    "\n",
    " # Compile the model.\n",
    "model_pointnet.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "# Train the model.\n",
    "history = model_pointnet.fit(\n",
    "    x_input_train, y_output_train,\n",
    "    epochs=50,\n",
    "    validation_data=(x_input_test, y_output_test),\n",
    "    callbacks=[tensorboard_callback],\n",
    "    batch_size=4\n",
    "    )\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "save_model_and_history(model_voxnet, history, \"pointnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_histories(histories, names):\n",
    "    for index, (history, name) in enumerate(zip(histories, names)):\n",
    "        for key, data in history.history.items():\n",
    "            plt.plot(data, label=name + \"-\" + key)\n",
    "    \n",
    "    # TODO consider: plt.savefig()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "plot_histories(histories, [\"voxnet\", \"pointnet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
