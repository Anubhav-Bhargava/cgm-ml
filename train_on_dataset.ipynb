{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import modelutils\n",
    "import utils\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import callbacks\n",
    "import pprint\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the latest dataset-paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180731-1325-voxelgrid-dataset.p\n",
      "20180731-1245-pointcloud-dataset.p\n"
     ]
    }
   ],
   "source": [
    "dataset_name_voxelgrid = sorted([x for x in glob.glob(\"*.p\") if \"voxelgrid-dataset\" in x])[-1]\n",
    "print(dataset_name_voxelgrid)\n",
    "\n",
    "dataset_name_pointcloud = sorted([x for x in glob.glob(\"*.p\") if \"pointcloud-dataset\" in x])[-1]\n",
    "print(dataset_name_pointcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = callbacks.TensorBoard()\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_history(model, history, name):\n",
    "    \n",
    "    print(\"Saving model and history...\")\n",
    "    \n",
    "    datetime_string = utils.get_datetime_string()\n",
    "    \n",
    "    model_name = datetime_string + \"-\" + name + \"-model.h5\"\n",
    "    model_voxnet.save(model_name)\n",
    "    print(\"Saved model to\" + model_name)\n",
    "\n",
    "    \n",
    "    history_name = datetime_string + \"-\" + name + \"-history.p\"\n",
    "    pickle.dump(history.history, open(history_name, \"wb\"))\n",
    "    print(\"Saved history to\" + history_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VoxNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "{   'dataset_size_test': 1000,\n",
      "    'dataset_size_train': 6000,\n",
      "    'input_type': 'voxelgrid',\n",
      "    'output_targets': ['height', 'weight'],\n",
      "    'random_seed': 666,\n",
      "    'voxel_size_meters': 0.1,\n",
      "    'voxelgrid_random_rotation': True,\n",
      "    'voxelgrid_target_shape': (32, 32, 32)}\n"
     ]
    }
   ],
   "source": [
    "dataset_name = dataset_name_voxelgrid\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "(x_input_train, y_output_train), (x_input_test, y_output_test), dataset_parameters = pickle.load(open(dataset_name, \"rb\"))\n",
    "pp.pprint(dataset_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 32, 32, 32, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 14, 14, 14, 32)    4032      \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 12, 12, 12, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 6, 6, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               884864    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 916,834\n",
      "Trainable params: 916,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 4045.5676 - mean_absolute_error: 50.0502\n",
      "Saving model and history...\n",
      "Saved model to20180731-1622-voxnet-model.h5\n",
      "Saved history to20180731-1622-voxnet-history.p\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 32)\n",
    "output_size = 2 \n",
    "model_voxnet = modelutils.create_voxnet_model_homepage(input_shape, output_size)\n",
    "model_voxnet.summary()\n",
    "\n",
    " # Compile the model.\n",
    "model_voxnet.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "# Train the model.\n",
    "history = model_voxnet.fit(\n",
    "    x_input_train, y_output_train,\n",
    "    epochs=50,\n",
    "    validation_data=(x_input_test, y_output_test),\n",
    "    callbacks=[tensorboard_callback]\n",
    "    )\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "save_model_and_history(model_voxnet, history, \"voxnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PointNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "{   'dataset_size_test': 500,\n",
      "    'dataset_size_train': 3000,\n",
      "    'input_type': 'pointcloud',\n",
      "    'output_targets': ['height', 'weight'],\n",
      "    'pointcloud_random_rotation': True,\n",
      "    'pointcloud_target_size': 30000,\n",
      "    'random_seed': 666}\n",
      "Ignoring shape: (27205, 4)\n",
      "Ignoring shape: (29891, 4)\n",
      "Ignoring shape: (26896, 4)\n",
      "Ignoring shape: (27134, 4)\n",
      "Ignoring shape: (29011, 4)\n",
      "Ignoring shape: (28040, 4)\n",
      "Ignoring shape: (26228, 4)\n",
      "Ignoring shape: (26965, 4)\n",
      "Ignoring shape: (26611, 4)\n",
      "Ignoring shape: (25740, 4)\n",
      "Ignoring shape: (27451, 4)\n",
      "Ignoring shape: (26563, 4)\n",
      "Ignoring shape: (26166, 4)\n",
      "Ignoring shape: (27564, 4)\n",
      "Ignoring shape: (27773, 4)\n",
      "Ignoring shape: (27134, 4)\n",
      "Ignoring shape: (27807, 4)\n",
      "Ignoring shape: (27089, 4)\n",
      "Ignoring shape: (27773, 4)\n",
      "Ignoring shape: (27709, 4)\n",
      "Ignoring shape: (25900, 4)\n",
      "Ignoring shape: (27288, 4)\n",
      "Ignoring shape: (27807, 4)\n",
      "Ignoring shape: (29601, 4)\n",
      "Ignoring shape: (26742, 4)\n",
      "Ignoring shape: (26304, 4)\n",
      "Ignoring shape: (26793, 4)\n",
      "Ignoring shape: (27205, 4)\n",
      "Ignoring shape: (27288, 4)\n",
      "Ignoring shape: (26503, 4)\n",
      "Ignoring shape: (29059, 4)\n",
      "Ignoring shape: (25740, 4)\n",
      "Ignoring shape: (27081, 4)\n",
      "Ignoring shape: (27357, 4)\n",
      "Ignoring shape: (27564, 4)\n",
      "Ignoring shape: (27727, 4)\n",
      "Ignoring shape: (27134, 4)\n",
      "Ignoring shape: (26503, 4)\n",
      "Ignoring shape: (26232, 4)\n",
      "Ignoring shape: (29891, 4)\n",
      "Ignoring shape: (26793, 4)\n",
      "Ignoring shape: (27451, 4)\n",
      "Ignoring shape: (27099, 4)\n",
      "Ignoring shape: (26247, 4)\n",
      "Ignoring shape: (26563, 4)\n",
      "Ignoring shape: (26907, 4)\n",
      "Ignoring shape: (26232, 4)\n",
      "Ignoring shape: (25900, 4)\n",
      "Ignoring shape: (27807, 4)\n",
      "Ignoring shape: (26965, 4)\n",
      "Ignoring shape: (27838, 4)\n",
      "Ignoring shape: (29059, 4)\n",
      "Ignoring shape: (27357, 4)\n",
      "Ignoring shape: (26949, 4)\n",
      "Ignoring shape: (29891, 4)\n",
      "Ignoring shape: (27113, 4)\n",
      "Ignoring shape: (27113, 4)\n",
      "Ignoring shape: (27451, 4)\n",
      "Ignoring shape: (26793, 4)\n",
      "Ignoring shape: (27838, 4)\n",
      "Ignoring shape: (26675, 4)\n",
      "Ignoring shape: (26965, 4)\n",
      "Ignoring shape: (26896, 4)\n",
      "Ignoring shape: (27642, 4)\n",
      "Ignoring shape: (27288, 4)\n",
      "Ignoring shape: (27422, 4)\n",
      "Training data input shape: (2934, 30000, 3)\n",
      "Training data output shape: (2934, 2)\n",
      "Testing data input shape: (2934, 30000, 3)\n",
      "Testing data output shape: (2934, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = dataset_name_pointcloud\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "(x_input_train, y_output_train), (x_input_test, y_output_test), dataset_parameters = pickle.load(open(dataset_name, \"rb\"))\n",
    "pp.pprint(dataset_parameters)\n",
    "\n",
    "def transform(x_input, y_output):\n",
    "\n",
    "    x_input_transformed = []\n",
    "    y_output_transformed = []\n",
    "    for input_sample, output_sample in zip(x_input_train, y_output_train):\n",
    "        if input_sample.shape[0] == 30000:\n",
    "            x_input_transformed.append(input_sample[:,0:3])\n",
    "            y_output_transformed.append(output_sample)\n",
    "        else:\n",
    "            # TODO maybe do some padding here?\n",
    "            print(\"Ignoring shape:\", input_sample.shape)\n",
    "            \n",
    "    x_input_transformed = np.array(x_input_transformed)\n",
    "    y_output_transformed = np.array(y_output_transformed)\n",
    "    return x_input_transformed, y_output_transformed\n",
    "    \n",
    "x_input_train, y_output_train = transform(x_input_train, y_output_train)\n",
    "x_input_test, y_output_test = transform(x_input_test, y_output_test)\n",
    "\n",
    "print(\"Training data input shape:\", x_input_train.shape)\n",
    "print(\"Training data output shape:\", y_output_train.shape)\n",
    "print(\"Testing data input shape:\", x_input_test.shape)\n",
    "print(\"Testing data output shape:\", y_output_test.shape)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 30000, 3)          0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 30000, 3)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 30000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 30000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 30000, 64)         4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30000, 64)         256       \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 30000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 30000, 64)         4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 30000, 128)        8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 30000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 30000, 1024)       132096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 30000, 1024)       4096      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1, 512)            524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1, 256)            131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 1, 256)            1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 256)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1, 2)              514       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 814,082\n",
      "Trainable params: 809,858\n",
      "Non-trainable params: 4,224\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 4s 4s/step - loss: 4045.5654 - mean_absolute_error: 50.0500\n",
      "Saving model and history...\n",
      "Saved model to20180731-1623-pointnet-model.h5\n",
      "Saved history to20180731-1623-pointnet-history.p\n"
     ]
    }
   ],
   "source": [
    "input_shape = (30000, 3)\n",
    "output_size = 2 \n",
    "model_pointnet = modelutils.create_point_net(input_shape, output_size)\n",
    "model_pointnet.summary()\n",
    "\n",
    " # Compile the model.\n",
    "model_pointnet.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "# Train the model.\n",
    "history = model_pointnet.fit(\n",
    "    x_input_train, y_output_train,\n",
    "    epochs=50,\n",
    "    validation_data=(x_input_test, y_output_test),\n",
    "    callbacks=[tensorboard_callback],\n",
    "    batch_size=8\n",
    "    )\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "save_model_and_history(model_voxnet, history, \"pointnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_histories(histories, names):\n",
    "    for index, (history, name) in enumerate(zip(histories, names)):\n",
    "        for key, data in history.history.items():\n",
    "            plt.plot(data, label=name + \"-\" + key)\n",
    "    \n",
    "    # TODO consider: plt.savefig()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "plot_histories(histories, [\"voxnet\", \"pointnet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
