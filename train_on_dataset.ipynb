{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import modelutils\n",
    "import utils\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import callbacks\n",
    "import pprint\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the latest dataset-paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./20180808-1431-voxelgrid-dataset.p\n",
      "./20180808-1437-pointcloud-dataset.p\n"
     ]
    }
   ],
   "source": [
    "dataset_name_voxelgrid = utils.get_latest_preprocessed_dataset(filter=\"voxelgrid-dataset\")\n",
    "print(dataset_name_voxelgrid)\n",
    "\n",
    "dataset_name_pointcloud = utils.get_latest_preprocessed_dataset(filter=\"pointcloud-dataset\")\n",
    "print(dataset_name_pointcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = callbacks.TensorBoard()\n",
    "histories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_history(model, history, name):\n",
    "    \n",
    "    print(\"Saving model and history...\")\n",
    "    \n",
    "    datetime_string = utils.get_datetime_string()\n",
    "    \n",
    "    model_name = datetime_string + \"-\" + name + \"-model.h5\"\n",
    "    model.save(model_name)\n",
    "    print(\"Saved model to\" + model_name)\n",
    "\n",
    "    \n",
    "    history_name = datetime_string + \"-\" + name + \"-history.p\"\n",
    "    pickle.dump(history.history, open(history_name, \"wb\"))\n",
    "    print(\"Saved history to\" + history_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VoxNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "{   'dataset_size_test': 1000,\n",
      "    'dataset_size_train': 6000,\n",
      "    'input_type': 'voxelgrid',\n",
      "    'output_targets': ['height', 'weight'],\n",
      "    'random_seed': 666,\n",
      "    'voxel_size_meters': 0.1,\n",
      "    'voxelgrid_random_rotation': True,\n",
      "    'voxelgrid_target_shape': (32, 32, 32)}\n"
     ]
    }
   ],
   "source": [
    "dataset_name = dataset_name_voxelgrid\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "(x_input_train, y_output_train, _), (x_input_test, y_output_test, _), dataset_parameters = pickle.load(open(dataset_name, \"rb\"))\n",
    "pp.pprint(dataset_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 32, 32, 32, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 14, 14, 14, 32)    4032      \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 12, 12, 12, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 6, 6, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               884864    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 916,834\n",
      "Trainable params: 916,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      " 672/6000 [==>...........................] - ETA: 25:05 - loss: 829.6429 - mean_absolute_error: 16.5494"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 32)\n",
    "output_size = 2 \n",
    "model_voxnet = modelutils.create_voxnet_model_homepage(input_shape, output_size)\n",
    "model_voxnet.summary()\n",
    "\n",
    " # Compile the model.\n",
    "model_voxnet.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "# Train the model.\n",
    "history = model_voxnet.fit(\n",
    "    x_input_train, y_output_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_input_test, y_output_test),\n",
    "    callbacks=[tensorboard_callback]\n",
    "    )\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "save_model_and_history(model_voxnet, history, \"voxnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training PointNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = dataset_name_pointcloud\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "(x_input_train, y_output_train, _), (x_input_test, y_output_test, _), dataset_parameters = pickle.load(open(dataset_name, \"rb\"))\n",
    "pp.pprint(dataset_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transform(x_input, y_output):\n",
    "\n",
    "    x_input_transformed = []\n",
    "    y_output_transformed = []\n",
    "    for input_sample, output_sample in zip(x_input_train, y_output_train):\n",
    "        if input_sample.shape[0] == 30000:\n",
    "            x_input_transformed.append(input_sample[:,0:3])\n",
    "            y_output_transformed.append(output_sample)\n",
    "        else:\n",
    "            # TODO maybe do some padding here?\n",
    "            print(\"Ignoring shape:\", input_sample.shape)\n",
    "            \n",
    "    x_input_transformed = np.array(x_input_transformed)\n",
    "    y_output_transformed = np.array(y_output_transformed)\n",
    "    return x_input_transformed, y_output_transformed\n",
    "    \n",
    "x_input_train, y_output_train = transform(x_input_train, y_output_train)\n",
    "x_input_test, y_output_test = transform(x_input_test, y_output_test)\n",
    "\n",
    "print(\"Training data input shape:\", x_input_train.shape)\n",
    "print(\"Training data output shape:\", y_output_train.shape)\n",
    "print(\"Testing data input shape:\", x_input_test.shape)\n",
    "print(\"Testing data output shape:\", y_output_test.shape)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_shape = (30000, 3)\n",
    "output_size = 2 \n",
    "model_pointnet = modelutils.create_point_net(input_shape, output_size)\n",
    "model_pointnet.summary()\n",
    "\n",
    " # Compile the model.\n",
    "model_pointnet.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "# Train the model.\n",
    "history = model_pointnet.fit(\n",
    "    x_input_train, y_output_train,\n",
    "    epochs=100,\n",
    "    validation_data=(x_input_test, y_output_test),\n",
    "    callbacks=[tensorboard_callback],\n",
    "    batch_size=4\n",
    "    )\n",
    "\n",
    "histories.append(history)\n",
    "\n",
    "save_model_and_history(model_pointnet, history, \"pointnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histories(histories, names):\n",
    "    for index, (history, name) in enumerate(zip(histories, names)):\n",
    "        for key, data in history.history.items():\n",
    "            plt.plot(data, label=name + \"-\" + key)\n",
    "    \n",
    "    # TODO consider: plt.savefig()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "plot_histories(histories, [\"voxnet\", \"pointnet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
