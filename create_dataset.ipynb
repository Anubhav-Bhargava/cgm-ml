{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset-Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datagenerator import DataGenerator\n",
    "import pickle\n",
    "import random\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing_jobs = multiprocessing.cpu_count()\n",
    "print(\"Going to spawn\", multiprocessing_jobs, \"jobs...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"datasetpath.txt\"):\n",
    "    dataset_path = open(\"datasetpath.txt\", \"r\").read().replace(\"\\n\", \"\")\n",
    "else:\n",
    "    dataset_path = \"../data\"\n",
    "\n",
    "# For creating voxelgrids.\n",
    "dataset_parameters_voxelgrids = {}\n",
    "dataset_parameters_voxelgrids[\"input_type\"] = \"voxelgrid\"\n",
    "dataset_parameters_voxelgrids[\"output_targets\"] = [\"height\", \"weight\"]    \n",
    "dataset_parameters_voxelgrids[\"random_seed\"] = 666\n",
    "dataset_parameters_voxelgrids[\"voxelgrid_target_shape\"] = (32, 32, 32)\n",
    "dataset_parameters_voxelgrids[\"voxel_size_meters\"] = 0.1\n",
    "dataset_parameters_voxelgrids[\"voxelgrid_random_rotation\"] = True\n",
    "dataset_parameters_voxelgrids[\"dataset_size_train\"] = 6000\n",
    "dataset_parameters_voxelgrids[\"dataset_size_test\"] = 1000\n",
    "\n",
    "# For creating pointclouds.\n",
    "dataset_parameters_pointclouds = {}\n",
    "dataset_parameters_pointclouds[\"input_type\"] = \"pointcloud\"\n",
    "dataset_parameters_pointclouds[\"output_targets\"] = [\"height\", \"weight\"]    \n",
    "dataset_parameters_pointclouds[\"random_seed\"] = 666\n",
    "dataset_parameters_pointclouds[\"pointcloud_target_size\"] = 30000\n",
    "dataset_parameters_pointclouds[\"pointcloud_random_rotation\"] = True\n",
    "dataset_parameters_pointclouds[\"dataset_size_train\"] = 3000\n",
    "dataset_parameters_pointclouds[\"dataset_size_test\"] = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the data-generator.\n",
    "Makes use of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datagenerator(dataset_parameters):\n",
    "    print(\"Creating data-generator...\")\n",
    "    datagenerator = DataGenerator(\n",
    "        dataset_path=dataset_path, \n",
    "        input_type=dataset_parameters[\"input_type\"], \n",
    "        output_targets=dataset_parameters[\"output_targets\"],\n",
    "        voxelgrid_target_shape=dataset_parameters.get(\"voxelgrid_target_shape\", None),\n",
    "        voxel_size_meters=dataset_parameters.get(\"voxel_size_meters\", None),\n",
    "        voxelgrid_random_rotation=dataset_parameters.get(\"voxelgrid_random_rotation\", None),\n",
    "        pointcloud_target_size=dataset_parameters.get(\"pointcloud_target_size\", None),\n",
    "        pointcloud_random_rotation=dataset_parameters.get(\"pointcloud_random_rotation\", None)\n",
    "    )\n",
    "    datagenerator.print_statistics()\n",
    "    return datagenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(datagenerator):\n",
    "    datagenerator.analyze_files()\n",
    "    datagenerator.analyze_targets()\n",
    "    datagenerator.analyze_pointclouds()\n",
    "    datagenerator.analyze_voxelgrids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the train-test-split and generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_generate(datagenerator, dataset_parameters):\n",
    "\n",
    "    # Do the split.\n",
    "    random.seed(dataset_parameters[\"random_seed\"])\n",
    "    qrcodes_shuffle = datagenerator.qrcodes[:]\n",
    "    random.shuffle(qrcodes_shuffle)\n",
    "    split_index = int(0.8 * len(qrcodes_shuffle))\n",
    "    qrcodes_train = sorted(qrcodes_shuffle[:split_index])\n",
    "    qrcodes_test = sorted(qrcodes_shuffle[split_index:])\n",
    "    del qrcodes_shuffle\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"QR-Codes for training:\", \" \".join(qrcodes_train))\n",
    "    print(\"\")\n",
    "    print(\"QR-Codes for testing:\", \" \".join(qrcodes_test))\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Generating training data...\")\n",
    "    dataset_train = next(datagenerator.generate(size=dataset_parameters[\"dataset_size_train\"], qrcodes_to_use=qrcodes_train, verbose=True, multiprocessing_jobs=multiprocessing_jobs))\n",
    "\n",
    "    print(\"Generating testing data...\")\n",
    "    dataset_test = next(datagenerator.generate(size=dataset_parameters[\"dataset_size_test\"], qrcodes_to_use=qrcodes_test, verbose=True, multiprocessing_jobs=multiprocessing_jobs))\n",
    "\n",
    "    print(\"Done.\")\n",
    "    return dataset_train, dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method for saving dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset_train, dataset_test, dataset_parameters):\n",
    "    print(\"Saving dataset...\")\n",
    "    datetime_string = utils.get_datetime_string()\n",
    "    dataset_name = datetime_string + \"-\" + dataset_parameters[\"input_type\"] + \"-dataset.p\"\n",
    "    pickle.dump((dataset_train, dataset_test, dataset_parameters), open(dataset_name, \"wb\"))\n",
    "    print(\"Saved \" + dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate with parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_parameters_to_use = []\n",
    "dataset_parameters_to_use.append(dataset_parameters_pointclouds)\n",
    "dataset_parameters_to_use.append(dataset_parameters_voxelgrids)\n",
    "\n",
    "for dataset_parameters in dataset_parameters_to_use:\n",
    "    \n",
    "    datagenerator = create_datagenerator(dataset_parameters)\n",
    "    #analyze(datagenerator)\n",
    "    \n",
    "    dataset_train, dataset_test = split_and_generate(datagenerator, dataset_parameters)\n",
    "    \n",
    "    save_dataset(dataset_train, dataset_test, dataset_parameters)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
