{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user ipyvolume\n",
    "# !pip install --user ipyvolume\n",
    "# !pip install --user pythreejs\n",
    "# !pip install --user PyntCloud\n",
    "# !jupyter nbextension install --user --py pythreejs\n",
    "# !jupyter nbextension enable --user --py pythreejs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! VTK not available. This might limit the functionality.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from ipywidgets import *\n",
    "sys.path.insert(0, \"..\")\n",
    "from IPython.display import clear_output\n",
    "from pathlib import Path\n",
    "from cgmcore import modelutils\n",
    "from keras import models\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import ipyvolume as ipv\n",
    "from pyntcloud import PyntCloud\n",
    "import glob2\n",
    "import os\n",
    "import pcl\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset_path\n",
    "\n",
    "Can be changed to visualize different set of point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/srv/data/etl/2018_10_23_14_48_20/SAM-SNG-081/1531894347034/pcd/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive search path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_search(path):\n",
    "    glob_search_path = os.path.join(path, \"**/*.pcd\")\n",
    "    pcd_paths = glob2.glob(glob_search_path)\n",
    "    # print(\"pcd_paths\", len(pcd_paths))\n",
    "    return pcd_paths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find all timestamps. Next step, so that we can look at the pictures ordered by time starting from the most recent one.\n",
    "def find_timestamps(self):\n",
    "        \"\"\"\n",
    "        Finds all timestamp\n",
    "        \"\"\"\n",
    "\n",
    "#To-do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "We can choose which model we want to use for the prediction in order to see the quality of our picture.\n",
    "We are going to use the last trained pointnet model, as requires least preprocessing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_path():\n",
    "    all_paths = glob.glob(\"../../data/output/*\")\n",
    "    date_times = []\n",
    "    for path in all_paths:\n",
    "        split = path.split(\"/\")[-1].split(\"-\")\n",
    "        date = split[0]\n",
    "        time = split[1]\n",
    "        date_time = date + \"-\" + time\n",
    "        date_times.append(date_time)\n",
    "    date_times = sorted(list(set(date_times)))\n",
    "    date_times = date_times[-10:]\n",
    "    #print(date_times)\n",
    "    model_pointnet_path = []\n",
    "    for date_time in date_times:\n",
    "        # Load all models for date-time and take the latest pointnet\n",
    "        model_paths = [path for path in all_paths if \"model\" in path and \"pointnet\" in path and date_time in path]\n",
    "        if model_paths:\n",
    "            # if we want more than one model, we should change this line using an append method instead\n",
    "            model_pointnet_path = model_paths\n",
    "    return model_pointnet_path\n",
    "\n",
    "        # print(model_pointnet)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative with load_weigths\n",
    "\n",
    "def get_model():\n",
    "    from cgmcore import modelutils\n",
    "    dataset_parameters_pointclouds = {}\n",
    "    dataset_parameters_pointclouds[\"pointcloud_target_size\"] = 10000\n",
    "    input_shape = (dataset_parameters_pointclouds[\"pointcloud_target_size\"], 3)\n",
    "    output_size = 1\n",
    "    model_pointnet = modelutils.create_point_net(input_shape, output_size, hidden_sizes = [64])\n",
    "    #model_pointnet.summary()\n",
    "    get_model_path()\n",
    "    #         for model_pointnet in model_paths: #the function load_model is not working\n",
    "#             \n",
    "#             model = models.load_model(model_pointnet)\n",
    "    #model_pointnet.load_weights('../../data/output/20181101-2145-pointnet-model-weights.h5') \n",
    "    #load_weight gives also an error\n",
    "    return model_pointnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10000, 3)          0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 10000, 3)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 10000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 10000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 10000, 64)         4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 10000, 64)         256       \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 10000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 10000, 64)         4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 10000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 10000, 128)        8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 10000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 10000, 1024)       132096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 10000, 1024)       4096      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 1024)           0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1, 64)             65600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1, 1)              65        \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 220,289\n",
      "Trainable params: 217,473\n",
      "Non-trainable params: 2,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_pointnet = get_model()\n",
    "model_pointnet.summary()        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complementary information to visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(array_for_pred):\n",
    "        indices = np.arange(0, array_for_pred.shape[0])\n",
    "        indices = np.random.choice(indices, 10000)\n",
    "        array_for_pred = array_for_pred[indices,0:3]\n",
    "        prediction = model_pointnet.predict(array_for_pred.reshape(1, 10000, 3))\n",
    "        return prediction\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(target_path):\n",
    "    common_path= '/'.join(target_path.split(\"/\")[:-2])\n",
    "    # print(common_path + '/target.txt')\n",
    "    \n",
    "    real_value = np.loadtxt(common_path + '/target.txt')\n",
    "    return real_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interface():\n",
    "    \n",
    "    import os\n",
    "    import shutil\n",
    "#     valid = ['y','n']\n",
    "#     valid2 = ['l','s']    \n",
    "    print('Is the picture good?') \n",
    "    button_yes = widgets.Button(description=\"yes\")\n",
    "    display(button_yes)\n",
    "    button_no = widgets.Button(description=\"no\")\n",
    "    display(button_no)\n",
    "    button_standing = widgets.Button(description=\"standing\")\n",
    "    \n",
    "    button_laying = widgets.Button(description=\"laying\")\n",
    "    \n",
    "    def on_button_standing_clicked(b):\n",
    "        print('Standing')\n",
    "        button_standing.close()\n",
    "        button_laying.close()\n",
    "        #send to standing\n",
    "        #shutil.copyfile(filePath, standing)\n",
    "        clear_output()\n",
    "        next(qc)\n",
    "        \n",
    "    def on_button_laying_clicked(b):\n",
    "        print(\"Ok we discard it\")\n",
    "        button_standing.close()\n",
    "        button_laying.close()\n",
    "        ipv.close()\n",
    "        #send to laying\n",
    "        #shutil.copyfile(filePath, laying)\n",
    "        clear_output()\n",
    "        next(qc)\n",
    "        \n",
    "    def on_button_yes_clicked(b):\n",
    "        print(\"Ok nice\")\n",
    "        button_yes.close()\n",
    "        button_no.close()\n",
    "        print('Is the child standing or laying?')\n",
    "        display(button_standing)\n",
    "        display(button_laying)\n",
    "        \n",
    "    def on_button_no_clicked(b):\n",
    "        print(\"Ok we discard it\")\n",
    "        button_yes.close()\n",
    "        button_no.close()\n",
    "        #send to discard\n",
    "        #shutil.copyfile(filepath, discarded)\n",
    "        clear_output()\n",
    "        next(qc)\n",
    "        \n",
    "    button_yes.on_click(on_button_yes_clicked)\n",
    "    button_no.on_click(on_button_no_clicked)\n",
    "    button_standing.on_click(on_button_standing_clicked)\n",
    "    button_laying.on_click(on_button_laying_clicked)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Selection of Pictures\n",
    "Ipyvolume visualization + Extra information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_check(path):\n",
    "    pcd_paths = path_search(path)\n",
    "    \n",
    "    #we are only going to create one image to avoid slowing down the notebook\n",
    "    #i = randint(0, len(pcd_paths))\n",
    "    for i in range(len(pcd_paths)):\n",
    "        print(i)\n",
    "        plt.clf\n",
    "        p = pcl.load(pcd_paths[i])\n",
    "        parray = np.asarray(p)\n",
    "        #this line is not working because we couldn't load the model\n",
    "        pred_value = prediction(parray)\n",
    "        real_value = get_target(pcd_paths[i])\n",
    "    #     standing = Path('standing') \n",
    "    #     discarded = Path('discarded')\n",
    "    #     laying = Path('laying')\n",
    "\n",
    "\n",
    "        # print(parray[:,1],parray[:,0], parray[:,2])\n",
    "        x,y,z = parray[:,1],parray[:,0], parray[:,2]\n",
    "        ipv.quickscatter(x,y,z, marker=\"sphere\", size = 0.5)\n",
    "        ipv.style.use(\"dark\")\n",
    "        ipv.show()\n",
    "        print('PREDICTED HEIGHT:{}, REAL HEIGHT: {}; ERROR: {}'.format(pred_value[0][0], real_value, np.abs(pred_value[0][0] - real_value)))\n",
    "        interface()\n",
    "        yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = quality_check(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cf3d90447f47379f65dcd3317db2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED HEIGHT:-0.0154360830783844, REAL HEIGHT: 78.6; ERROR: 78.61543608307838\n",
      "Is the picture good?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d8d4b5b09a4e0e8cf26eca3fe12d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='yes', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bb60dfed254d15829544e8f9eb948c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='no', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "next(qc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
