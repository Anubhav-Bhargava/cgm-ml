{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tristanbehrens/Development/python-venvs/venv-3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from datagenerator import DataGenerator\n",
    "import datetime\n",
    "import pickle\n",
    "from pyntcloud import PyntCloud\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hook to the proper dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"datasetpath.txt\"):\n",
    "    dataset_path = open(\"datasetpath.txt\", \"r\").read().replace(\"\\n\", \"\")\n",
    "else:\n",
    "    dataset_path = \"../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a data-generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jpg_paths 4511\n",
      "pcd_paths 1360\n",
      "json_paths_personal 40\n",
      "json_paths_measures 74\n",
      "QR-Codes:\n",
      "SAM-02-003-01\n",
      "SAM-GOV-001\n",
      "SAM-GOV-002\n",
      "SAM-GOV-003\n",
      "SAM-GOV-004\n",
      "SAM-GOV-005\n",
      "SAM-GOV-008\n",
      "SAM-GOV-011\n",
      "SAM-GOV-012\n",
      "SAM-GOV-013\n",
      "SAM-GOV-014\n",
      "SAM-GOV-023\n",
      "SAM-GOV-025\n",
      "SAM-GOV-026\n",
      "SAM-GOV-033\n",
      "SAM-GOV-034\n",
      "SAM-GOV-035\n",
      "SAM-GOV-036\n",
      "SAM-GOV-037\n",
      "SAM-GOV-038\n",
      "SAM-GOV-041\n",
      "SAM-GOV-042\n",
      "SAM-GOV-043\n",
      "SAM-GOV-044\n",
      "SAM-GOV-099\n",
      "SAM-SNG-011\n",
      "SAM-SNG-012\n",
      "SAM-SNG-013\n",
      "SAM-SNG-014\n",
      "SAM-SNG-015\n",
      "SAM-SNG-016\n",
      "SAM-SNG-021\n",
      "SAM-SNG-036\n",
      "SAM-SNG-066\n",
      "SAM-SNG-067\n",
      "SAM-SNG-072\n",
      "SAM-SNG-091\n",
      "SAM-SNG-096\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "data_generator = DataGenerator(dataset_path=dataset_path, input_type=\"voxelgrid\", output_targets=[\"height\", \"weight\"])\n",
    "\n",
    "print(\"jpg_paths\", len(data_generator.jpg_paths))\n",
    "print(\"pcd_paths\", len(data_generator.pcd_paths))\n",
    "print(\"json_paths_personal\", len(data_generator.json_paths_personal))\n",
    "print(\"json_paths_measures\", len(data_generator.json_paths_measures))\n",
    "print(\"QR-Codes:\\n\" + \"\\n\".join(data_generator.qrcodes))\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the train-validate-split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QR-Codes train:\n",
      "SAM-GOV-023 SAM-GOV-041 SAM-GOV-033 SAM-GOV-037 SAM-GOV-012 SAM-GOV-099 SAM-GOV-001 SAM-GOV-035 SAM-GOV-002 SAM-GOV-038 SAM-GOV-008 SAM-GOV-025 SAM-GOV-034 SAM-GOV-036 SAM-GOV-004 SAM-GOV-014 SAM-GOV-043 SAM-GOV-011 SAM-GOV-042\n",
      "\n",
      "QR-Codes validate:\n",
      "SAM-GOV-013 SAM-GOV-026 SAM-GOV-003 SAM-GOV-044 SAM-GOV-005\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Ensure that the split is always the same.\n",
    "random.seed(108)\n",
    "\n",
    "# Filter and shuffle the QR-Codes.\n",
    "qrcodes_shuffle = list(data_generator.qrcodes)\n",
    "qrcodes_shuffle = [qrcode for qrcode in qrcodes_shuffle if qrcode.startswith(\"SAM-GOV\")]\n",
    "random.shuffle(qrcodes_shuffle)\n",
    "\n",
    "# Do the split.\n",
    "split_index = int(0.8 * len(qrcodes_shuffle))\n",
    "qrcodes_train = qrcodes_shuffle[:split_index]\n",
    "qrcodes_validate = qrcodes_shuffle[split_index:]\n",
    "del qrcodes_shuffle\n",
    "\n",
    "# Print statistics.\n",
    "print(\"QR-Codes train:\")\n",
    "print(\" \".join(qrcodes_train))\n",
    "print(\"\")\n",
    "print(\"QR-Codes validate:\")\n",
    "print(\" \".join(qrcodes_validate))\n",
    "print(\"\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for network generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 32, 32, 32, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 14, 14, 14, 32)    4032      \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 12, 12, 12, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 6, 6, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               884864    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 916,834\n",
      "Trainable params: 916,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_dense_model(input_shape, output_size):\n",
    "    \n",
    "    model = models.Sequential(name=\"baseline-dense\")\n",
    "    model.add(layers.Flatten(input_shape=input_shape))\n",
    "    model.add(layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(layers.Dense(output_size))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_voxnet_model_small(input_shape, output_size):\n",
    "    \"\"\" See: http://dimatura.net/publications/3dcnn_lz_maturana_scherer_icra15.pdf \"\"\"\n",
    "    \n",
    "    #Trainable params: 301,378\n",
    "    model = models.Sequential(name=\"C7-F32-P2-C5-F64-P2-D512\")\n",
    "    model.add(layers.Reshape(target_shape=input_shape + (1,), input_shape=input_shape))\n",
    "    model.add(layers.Conv3D(32, (7, 7, 7), activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling3D((4, 4, 4)))\n",
    "    model.add(layers.Conv3D(64, (5, 5, 5), activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling3D((2, 2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(layers.Dense(output_size))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_voxnet_model_big(input_shape, output_size):\n",
    "    \"\"\" See: http://dimatura.net/publications/3dcnn_lz_maturana_scherer_icra15.pdf \"\"\"\n",
    "    \n",
    "    # Trainable params: 7,101,442\n",
    "    model = models.Sequential(name=\"C7-F64-P4-D512\")\n",
    "    model.add(layers.Reshape(target_shape=input_shape + (1,), input_shape=input_shape))\n",
    "    model.add(layers.Conv3D(64, (7, 7, 7), activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling3D((4, 4, 4)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation=\"relu\"))\n",
    "    model.add(layers.Dense(output_size))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def create_voxnet_model_homepage(input_shape, output_size):\n",
    "    \"\"\" See: http://dimatura.net/publications/3dcnn_lz_maturana_scherer_icra15.pdf \"\"\"\n",
    "    \n",
    "    # Trainable params: 916,834\n",
    "    model = models.Sequential(name=\"VoxNetHomepage\")\n",
    "    model.add(layers.Reshape(target_shape=input_shape + (1,), input_shape=input_shape))\n",
    "    model.add(layers.Conv3D(32, (5, 5, 5), strides=(2, 2, 2), activation=\"relu\"))\n",
    "    model.add(layers.Conv3D(32, (3, 3, 3), strides=(1, 1, 1), activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling3D((2, 2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(layers.Dense(output_size))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train several nets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: baseline-dense\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 4,202,818\n",
      "Trainable params: 4,202,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 255s 8s/step - loss: 2856.1291 - mean_absolute_error: 41.1831 - val_loss: 2409.1778 - val_mean_absolute_error: 37.7164\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 65s 2s/step - loss: 2573.1764 - mean_absolute_error: 38.3627 - val_loss: 2103.5901 - val_mean_absolute_error: 34.1033\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 19s 599ms/step - loss: 2114.1086 - mean_absolute_error: 33.3147 - val_loss: 1585.6616 - val_mean_absolute_error: 28.4384\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 11s 341ms/step - loss: 1518.5249 - mean_absolute_error: 28.2375 - val_loss: 991.8116 - val_mean_absolute_error: 22.9254\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 880.7670 - mean_absolute_error: 21.4398 - val_loss: 408.8201 - val_mean_absolute_error: 14.4436\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 3s 107ms/step - loss: 327.9832 - mean_absolute_error: 12.3608 - val_loss: 80.4452 - val_mean_absolute_error: 5.1457\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 87.4732 - mean_absolute_error: 5.7485 - val_loss: 39.2991 - val_mean_absolute_error: 4.3700\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 46.3883 - mean_absolute_error: 4.6098 - val_loss: 34.5155 - val_mean_absolute_error: 4.3105\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 3s 84ms/step - loss: 37.6982 - mean_absolute_error: 4.2611 - val_loss: 35.9553 - val_mean_absolute_error: 4.2125\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 3s 81ms/step - loss: 21.3355 - mean_absolute_error: 3.3040 - val_loss: 25.9917 - val_mean_absolute_error: 3.6850\n",
      "Training: C7-F32-P2-C5-F64-P2-D512\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 32, 32, 32, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 26, 26, 26, 32)    11008     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 6, 6, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 2, 2, 2, 64)       256064    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 1, 1, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 301,378\n",
      "Trainable params: 301,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " 4/32 [==>...........................] - ETA: 34:42 - loss: 2946.1097 - mean_absolute_error: 41.9447"
     ]
    }
   ],
   "source": [
    "# Parameters.\n",
    "batch_size = 32\n",
    "step_per_epoch = 32\n",
    "epochs = 10\n",
    "validation_steps = 8\n",
    "\n",
    "\n",
    "# Create the models.\n",
    "models_to_train = []\n",
    "models_to_train.append(create_dense_model(data_generator.get_input_shape(), data_generator.get_output_size()))\n",
    "models_to_train.append(create_voxnet_model_small(data_generator.get_input_shape(), data_generator.get_output_size()))\n",
    "models_to_train.append(create_voxnet_model_big(data_generator.get_input_shape(), data_generator.get_output_size()))\n",
    "models_to_train.append(create_voxnet_model_homepage(data_generator.get_input_shape(), data_generator.get_output_size()))\n",
    "\n",
    "# Train the models.\n",
    "histories = []\n",
    "for model in models_to_train:\n",
    "\n",
    "    # Some output.\n",
    "    print(\"Training:\", model.name)\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(\n",
    "            optimizer=\"rmsprop\",\n",
    "            loss=\"mse\",\n",
    "            metrics=[\"mae\"]\n",
    "        )\n",
    "    \n",
    "    # Train the model.\n",
    "    history = model.fit_generator(\n",
    "        data_generator.generate(size=batch_size, qrcodes_to_use=qrcodes_train),\n",
    "        steps_per_epoch=step_per_epoch,\n",
    "        epochs=epochs,\n",
    "        validation_data=data_generator.generate(size=batch_size, qrcodes_to_use=qrcodes_validate),\n",
    "        validation_steps=validation_steps)\n",
    "    \n",
    "    histories.append(history)\n",
    "    print(\"Done.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_string = datetime.datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "# Save the models and histories.    \n",
    "for model in models_to_train:\n",
    "    model_name = datetime_string + \"-\" + model.name\n",
    "    model_path = os.path.join(model_name)\n",
    "    #model.save(model_path + \".h5\")\n",
    "    #pickle.dump(history, open(model_path + \".p\", \"wb\"))\n",
    "    print(\"Model saved to:\", model_path)\n",
    "    \n",
    "print(\"All saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render histories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, history in histories:\n",
    "    model = models_to_train[i]\n",
    "    for key, data in history.history.items():\n",
    "        plt.plot(data, label=model.name + \"-\" + key)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
